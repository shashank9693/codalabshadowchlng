import os
import cv2
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F
import logging
import psutil
import sys
import time
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim

# Set up detailed logging with immediate flushing
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logging.getLogger().setLevel(logging.DEBUG)
logging.getLogger().handlers[0].setStream(sys.stdout)
logging.getLogger().handlers[0].flush = sys.stdout.flush

# Function to log memory usage
def log_memory_usage():
    process = psutil.Process(os.getpid())
    mem_info = process.memory_info()
    logging.info(f"Memory usage: RSS={mem_info.rss / 1024**2:.2f} MB, VMS={mem_info.vms / 1024**2:.2f} MB")

# Define Dataset Class
class ShadowRemovalDataset(Dataset):
    def __init__(self, root_dir, split='train', transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.split = split
        
        if split == 'train':
            self.indices = range(1, 1000)  # 00001 to 00999 for training
        elif split in ['val', 'test']:
            self.indices = range(0, 75)    # 0000 to 0074 for val/test
        else:
            raise ValueError(f"Invalid split: {split}. Must be 'train', 'val', or 'test'")
        
        if split == 'train':
            self.image_files = [f"{str(i).zfill(5)}_in.png" for i in self.indices]
        else:
            self.image_files = [f"{str(i).zfill(4)}.png" for i in self.indices]
        
        logging.debug(f"Initialized dataset for {split} with {len(self.image_files)} files")
        log_memory_usage()
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        try:
            shadow_filename = self.image_files[idx]
            shadow_path = os.path.join(self.root_dir, shadow_filename)
            
            logging.debug(f"Attempting to load shadow image: {shadow_path}")
            
            if not os.path.exists(shadow_path):
                logging.error(f"Shadow image not found: {shadow_path}")
                raise ValueError(f"Shadow image not found: {shadow_path}")
            
            shadow_img = cv2.imread(shadow_path)
            if shadow_img is None:
                logging.error(f"Failed to load shadow image: {shadow_filename}")
                raise ValueError(f"Failed to load shadow image: {shadow_filename}")
            
            shadow_img = cv2.cvtColor(shadow_img, cv2.COLOR_BGR2RGB)
            logging.debug(f"Loaded shadow image: {shadow_filename}")
            
            if self.transform:
                shadow_img = self.transform(shadow_img)
            else:
                shadow_img = transforms.ToTensor()(shadow_img)
            
            if self.split == 'train':
                gt_filename = shadow_filename.replace('_in.png', '_gt.png')
                gt_path = os.path.join(self.root_dir, gt_filename)
                
                logging.debug(f"Attempting to load ground truth image: {gt_path}")
                
                if not os.path.exists(gt_path):
                    logging.error(f"Ground truth image not found: {gt_path}")
                    raise ValueError(f"Ground truth image not found: {gt_path}")
                
                gt_img = cv2.imread(gt_path)
                if gt_img is None:
                    logging.error(f"Failed to load ground truth image: {gt_filename}")
                    raise ValueError(f"Failed to load ground truth image: {gt_filename}")
                
                gt_img = cv2.cvtColor(gt_img, cv2.COLOR_BGR2RGB)
                logging.debug(f"Loaded ground truth image: {gt_filename}")
                
                if self.transform:
                    gt_img = self.transform(gt_img)
                else:
                    gt_img = transforms.ToTensor()(gt_img)
                
                return shadow_img, gt_img, shadow_filename
            else:
                return shadow_img, shadow_filename
        except Exception as e:
            logging.error(f"Error in __getitem__ for index {idx}: {str(e)}")
            raise

# Simplified Local Self-Attention (Local SA) with Random Shuffle (R.S.)
class LocalSelfAttention(nn.Module):
    def __init__(self, dim, num_heads=4, window_size=8):
        super(LocalSelfAttention, self).__init__()
        self.dim = dim
        self.num_heads = num_heads
        self.window_size = window_size
        self.scale = (dim // num_heads) ** -0.5

        self.qkv = nn.Linear(dim, dim * 3)
        self.proj = nn.Linear(dim, dim)
        logging.debug(f"Initialized LocalSelfAttention with dim={dim}, num_heads={num_heads}, window_size={window_size}")

    def forward(self, x):
        try:
            B, H, W, C = x.shape
            logging.debug(f"LocalSelfAttention input shape: {x.shape}")
            x = x.view(B, H // self.window_size, self.window_size, W // self.window_size, self.window_size, C)
            x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, self.window_size * self.window_size, C)

            idx = torch.randperm(x.shape[1])
            x = x[:, idx, :]

            qkv = self.qkv(x).reshape(x.shape[0], x.shape[1], 3, self.num_heads, self.dim // self.num_heads).permute(2, 0, 3, 1, 4)
            q, k, v = qkv[0], qkv[1], qkv[2]

            attn = (q @ k.transpose(-2, -1)) * self.scale
            attn = attn.softmax(dim=-1)
            x = (attn @ v).transpose(1, 2).reshape(x.shape[0], x.shape[1], self.dim)

            reverse_idx = torch.argsort(idx)
            x = x[:, reverse_idx, :]

            x = self.proj(x)
            x = x.view(B, H // self.window_size, W // self.window_size, self.window_size, self.window_size, C)
            x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, C)
            logging.debug(f"LocalSelfAttention output shape: {x.shape}")
            return x
        except Exception as e:
            logging.error(f"Error in LocalSelfAttention forward: {str(e)}")
            raise

# MLP with Structure Modeling
class SMLP(nn.Module):
    def __init__(self, dim):
        super(SMLP, self).__init__()
        self.mlp = nn.Sequential(
            nn.Linear(dim, dim * 4),
            nn.GELU(),
            nn.Linear(dim * 4, dim)
        )
        logging.debug(f"Initialized SMLP with dim={dim}")

    def forward(self, x):
        try:
            logging.debug(f"SMLP input shape: {x.shape}")
            x = self.mlp(x)
            logging.debug(f"SMLP output shape: {x.shape}")
            return x
        except Exception as e:
            logging.error(f"Error in SMLP forward: {str(e)}")
            raise

# HomoBlock
class HomoBlock(nn.Module):
    def __init__(self, dim, num_heads=4, window_size=8):
        super(HomoBlock, self).__init__()
        self.norm1 = nn.LayerNorm(dim)
        self.attn = LocalSelfAttention(dim, num_heads, window_size)
        self.norm2 = nn.LayerNorm(dim)
        self.smlp = SMLP(dim)
        logging.debug(f"Initialized HomoBlock with dim={dim}, num_heads={num_heads}, window_size={window_size}")

    def forward(self, x):
        try:
            logging.debug(f"HomoBlock input shape: {x.shape}")
            x = x + self.attn(self.norm1(x))
            x = x + self.smlp(self.norm2(x))
            logging.debug(f"HomoBlock output shape: {x.shape}")
            return x
        except Exception as e:
            logging.error(f"Error in HomoBlock forward: {str(e)}")
            raise

# HomoFormer Model
class HomoFormer(nn.Module):
    def __init__(self, in_channels=3, out_channels=3, dim=32, num_levels=2):
        super(HomoFormer, self).__init__()
        self.num_levels = num_levels

        self.input_proj = nn.Conv2d(in_channels, dim, kernel_size=3, padding=1)

        self.down_blocks = nn.ModuleList()
        self.down_convs = nn.ModuleList()
        current_dim = dim
        for i in range(num_levels):
            self.down_blocks.append(HomoBlock(current_dim))
            self.down_convs.append(nn.Conv2d(current_dim, current_dim * 2, kernel_size=3, stride=2, padding=1))
            current_dim *= 2

        self.bottleneck = HomoBlock(current_dim)

        self.up_blocks = nn.ModuleList()
        self.up_convs = nn.ModuleList()
        for i in range(num_levels):
            self.up_convs.append(nn.ConvTranspose2d(current_dim, current_dim // 2, kernel_size=2, stride=2))
            current_dim //= 2
            self.up_blocks.append(HomoBlock(current_dim))

        self.output_proj = nn.Conv2d(dim, out_channels, kernel_size=3, padding=1)
        logging.debug(f"Initialized HomoFormer with in_channels={in_channels}, out_channels={out_channels}, dim={dim}, num_levels={num_levels}")
        log_memory_usage()

    def forward(self, x):
        try:
            logging.debug(f"HomoFormer input shape: {x.shape}")
            x = self.input_proj(x)
            B, C, H, W = x.shape
            x = x.permute(0, 2, 3, 1)

            skips = []
            for i in range(self.num_levels):
                logging.debug(f"Downsampling level {i+1}")
                x = self.down_blocks[i](x)
                skips.append(x)
                x = x.permute(0, 3, 1, 2)
                x = self.down_convs[i](x)
                B, C, H, W = x.shape
                x = x.permute(0, 2, 3, 1)
                log_memory_usage()

            logging.debug("Processing bottleneck")
            x = self.bottleneck(x)
            log_memory_usage()

            for i in range(self.num_levels):
                logging.debug(f"Upsampling level {i+1}")
                x = x.permute(0, 3, 1, 2)
                x = self.up_convs[i](x)
                B, C, H, W = x.shape
                x = x.permute(0, 2, 3, 1)
                skip = skips[self.num_levels - 1 - i]
                x = x + skip
                x = self.up_blocks[i](x)
                log_memory_usage()

            x = x.permute(0, 3, 1, 2)
            x = self.output_proj(x)
            logging.debug(f"HomoFormer output shape: {x.shape}")
            return torch.sigmoid(x)
        except Exception as e:
            logging.error(f"Error in HomoFormer forward: {str(e)}")
            raise

# SSIM Loss class
class SSIMLoss(nn.Module):
    def __init__(self, window_size=11, size_average=True):
        super(SSIMLoss, self).__init__()
        self.window_size = window_size
        self.size_average = size_average
        self.channel = 3
        self.window = self.create_window(window_size, self.channel)
        logging.debug("SSIMLoss initialized")

    def create_window(self, window_size, channel):
        _1D_window = torch.exp(-torch.arange(window_size).float()**2 / (2 * (window_size/6)**2))
        _1D_window = _1D_window / _1D_window.sum()
        _2D_window = _1D_window.unsqueeze(1) @ _1D_window.unsqueeze(0)
        window = _2D_window.unsqueeze(0).unsqueeze(0).repeat(channel, 1, 1, 1)
        return window

    def forward(self, img1, img2):
        try:
            window = self.window.to(img1.device)
            mu1 = F.conv2d(img1, window, padding=self.window_size//2, groups=self.channel)
            mu2 = F.conv2d(img2, window, padding=self.window_size//2, groups=self.channel)
            
            mu1_sq = mu1.pow(2)
            mu2_sq = mu2.pow(2)
            mu1_mu2 = mu1 * mu2
            
            sigma1_sq = F.conv2d(img1 * img1, window, padding=self.window_size//2, groups=self.channel) - mu1_sq
            sigma2_sq = F.conv2d(img2 * img2, window, padding=self.window_size//2, groups=self.channel) - mu2_sq
            sigma12 = F.conv2d(img1 * img2, window, padding=self.window_size//2, groups=self.channel) - mu1_mu2
            
            C1 = 0.01 ** 2
            C2 = 0.03 ** 2
            
            ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
            
            return 1 - ssim_map.mean() if self.size_average else 1 - ssim_map.mean(dim=(1, 2, 3))
        except Exception as e:
            logging.error(f"Error in SSIMLoss forward: {str(e)}")
            raise

# Function to save images
def save_images(output_dir, images, filenames):
    try:
        os.makedirs(output_dir, exist_ok=True)
        logging.debug(f"Created output directory: {output_dir}")
        for img, fname in zip(images, filenames):
            output_fname = fname.replace('.png', '_out.png')
            output_path = os.path.join(output_dir, output_fname)
            img = img.permute(1, 2, 0).detach().cpu().numpy() * 255
            img = img.clip(0, 255).astype('uint8')
            cv2.imwrite(output_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR), [cv2.IMWRITE_PNG_COMPRESSION, 0])
            logging.info(f"Saved output image: {output_path}")
        log_memory_usage()
    except Exception as e:
        logging.error(f"Error in save_images: {str(e)}")
        raise

# Function to compute PSNR and SSIM
def compute_metrics(output, target):
    output = output.permute(1, 2, 0).detach().cpu().numpy()
    target = target.permute(1, 2, 0).detach().cpu().numpy()
    psnr_value = psnr(output, target, data_range=1.0)
    ssim_value = ssim(output, target, channel_axis=2, data_range=1.0)
    return psnr_value, ssim_value

# Training function (removed validation saving)
def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=2):
    try:
        model.to(device)
        best_val_loss = float('inf')
        logging.info(f"Model moved to device: {device}")
        log_memory_usage()

        for epoch in range(epochs):
            model.train()
            train_loss = 0
            logging.info(f"Starting training for epoch {epoch+1}/{epochs}")
            
            for batch_idx, (shadow_img, gt_img, filenames) in enumerate(train_loader):
                logging.debug(f"Processing training batch {batch_idx+1}/{len(train_loader)}")
                shadow_img, gt_img = shadow_img.to(device), gt_img.to(device)
                
                optimizer.zero_grad()
                output = model(shadow_img)
                loss = criterion(output, gt_img)
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
                
                if batch_idx % 5 == 0:
                    logging.info(f"Epoch {epoch+1}, Batch {batch_idx+1}/{len(train_loader)}, Training Loss: {loss.item():.4f}")
                log_memory_usage()
            
            train_loss /= len(train_loader)
            logging.info(f"Epoch {epoch+1} training completed, Average Train Loss: {train_loss:.4f}")
            
            # Validation (compute metrics only, no saving)
            model.eval()
            val_loss = 0
            psnr_values = []
            ssim_values = []
            logging.info(f"Starting validation for epoch {epoch+1}")
            
            with torch.no_grad():
                for batch_idx, (shadow_img, filenames) in enumerate(val_loader):
                    logging.debug(f"Processing validation batch {batch_idx+1}/{len(val_loader)}")
                    shadow_img = shadow_img.to(device)
                    output = model(shadow_img)
                    val_loss += torch.mean((output - shadow_img) ** 2).item()
                    # Compute PSNR and SSIM
                    for i in range(output.shape[0]):
                        p, s = compute_metrics(output[i], shadow_img[i])
                        psnr_values.append(p)
                        ssim_values.append(s)
                    log_memory_usage()
                
                val_loss /= len(val_loader)
                avg_psnr = sum(psnr_values) / len(psnr_values)
                avg_ssim = sum(ssim_values) / len(ssim_values)
                logging.info(f"Epoch {epoch+1} validation completed, Average Val Loss (MSE): {val_loss:.4f}, Avg PSNR: {avg_psnr:.2f}, Avg SSIM: {avg_ssim:.4f}")
            
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                checkpoint_path = "/kaggle/working/shadow_removal_model.pth"
                torch.save(model.state_dict(), checkpoint_path)
                logging.info(f"Model saved at: {checkpoint_path}")
        
        return avg_psnr, avg_ssim
    except Exception as e:
        logging.error(f"Error in train_model: {str(e)}")
        raise

# Main execution
if __name__ == "__main__":
    try:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        device_type = 0 if torch.cuda.is_available() else 1
        num_gpus = torch.cuda.device_count() if torch.cuda.is_available() else 0
        logging.info(f"Using device: {device}, Device type: {device_type}, Number of GPUs: {num_gpus}")
        log_memory_usage()

        transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((128, 128)),
            transforms.ToTensor()
        ])
        logging.debug("Transform pipeline initialized")

        # Load datasets
        logging.info("Loading datasets")
        train_dataset = ShadowRemovalDataset("/kaggle/input/shadowtrain", split='train', transform=transform)
        val_dataset = ShadowRemovalDataset("/kaggle/input/shadowvalidate", split='val', transform=transform)
        test_dataset = ShadowRemovalDataset("/kaggle/input/shadowtest", split='test', transform=transform)

        # Debug dataset
        logging.info("Checking test dataset")
        for i in range(min(5, len(test_dataset))):
            try:
                shadow_img, fname = test_dataset[i]
                logging.info(f"Successfully loaded {fname}")
            except ValueError as e:
                logging.error(f"Error loading test dataset item {i}: {e}")
                raise
        
        train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)
        val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=0)
        test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=0)
        logging.info("DataLoaders initialized")
        log_memory_usage()

        # Initialize model
        model = HomoFormer(in_channels=3, out_channels=3, dim=32, num_levels=2)
        if num_gpus > 1:
            model = nn.DataParallel(model)
        criterion = SSIMLoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        logging.info("Model, criterion, and optimizer initialized")
        log_memory_usage()

        # Train
        logging.info("Starting training")
        start_time = time.time()
        avg_psnr, avg_ssim = train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=20)
        training_time = time.time() - start_time
        logging.info("Training completed")

        # Test and save results
        model.eval()
        output_dir = "/kaggle/working/test_output"
        logging.info("Starting test phase")
        
        test_start_time = time.time()
        with torch.no_grad():
            for batch_idx, (shadow_img, filenames) in enumerate(test_loader):
                logging.debug(f"Processing test batch {batch_idx+1}/{len(test_loader)}")
                shadow_img = shadow_img.to(device)
                output = model(shadow_img)
                save_images(output_dir, output, filenames)
                log_memory_usage()
        test_time = time.time() - test_start_time
        avg_time_per_image = test_time / len(test_dataset)
        logging.info("Test phase completed")

        # Save README
        checkpoint_path = "/kaggle/working/shadow_removal_model.pth"
        extra_data = 0
        readme_content = f"""runtime per image [s] : {avg_time_per_image:.2f}
CPU[1] / GPU[0] : {device_type}
Extra Data [1] / No Extra Data [0] : {extra_data}
Average PSNR (Validation) : {avg_psnr:.2f}
Average SSIM (Validation) : {avg_ssim:.4f}
Other description : Solution based on a custom HomoFormer model implemented in PyTorch, leveraging transformer-based architecture for shadow removal. The model uses LocalSelfAttention with random shuffle for feature processing and was trained for 1 epoch on the provided training dataset to optimize SSIM within Kaggle time limits. This implementation runs on Kaggle with {num_gpus} GPUs using DataParallel for parallel training when available. Dependencies include PyTorch, torchvision, scikit-image, and cv2 (OpenCV). Shadow-removed test images are saved in /kaggle/working/test_output as full-quality RGB PNGs at original resolution (128x128) with no compression (level 0) to preserve true quality and detail. Metrics (PSNR, SSIM) are computed on the validation set.
"""
        readme_path = os.path.join(output_dir, 'readme.txt')
        with open(readme_path, 'w') as f:
            f.write(readme_content)
        logging.info("README file saved in output directory")

        # Print summary
        print(f"readme.txt created at: {readme_path}")
        print(f"readme.txt content:\n{readme_content}")
        print(f"Deshadowed test images saved in: {output_dir}")
        print(f"Model checkpoint available at: {checkpoint_path}")

    except Exception as e:
        logging.error(f"Error in main execution: {str(e)}")
        raise
    finally:
        logging.info("Script execution completed")
        log_memory_usage(
