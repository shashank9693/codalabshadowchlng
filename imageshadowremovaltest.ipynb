{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "120ec9a1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-22T06:11:40.025773Z",
     "iopub.status.busy": "2025-03-22T06:11:40.025327Z",
     "iopub.status.idle": "2025-03-22T06:12:33.321732Z",
     "shell.execute_reply": "2025-03-22T06:12:33.320956Z"
    },
    "papermill": {
     "duration": 53.301631,
     "end_time": "2025-03-22T06:12:33.323155",
     "exception": false,
     "start_time": "2025-03-22T06:11:40.021524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.26.4\r\n",
      "Uninstalling numpy-1.26.4:\r\n",
      "  Successfully uninstalled numpy-1.26.4\r\n",
      "Found existing installation: scipy 1.13.1\r\n",
      "Uninstalling scipy-1.13.1:\r\n",
      "  Successfully uninstalled scipy-1.13.1\r\n",
      "Found existing installation: scikit-image 0.25.0\r\n",
      "Uninstalling scikit-image-0.25.0:\r\n",
      "  Successfully uninstalled scikit-image-0.25.0\r\n",
      "Collecting numpy==1.23.5\r\n",
      "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\r\n",
      "Collecting scipy==1.9.3\r\n",
      "  Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting scikit-image==0.19.3\r\n",
      "  Downloading scikit_image-0.19.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\r\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.3) (3.4.2)\r\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.3) (11.0.0)\r\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.3) (2.36.1)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.3) (2024.12.12)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.3) (1.8.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.3) (24.2)\r\n",
      "Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scikit_image-0.19.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: numpy, scipy, scikit-image\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\r\n",
      "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\r\n",
      "albumentations 1.4.20 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\r\n",
      "bayesian-optimization 2.0.3 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\r\n",
      "bigframes 1.29.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\r\n",
      "chex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\r\n",
      "featuretools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\r\n",
      "featuretools 1.31.0 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\r\n",
      "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\r\n",
      "jax 0.4.33 requires scipy>=1.10, but you have scipy 1.9.3 which is incompatible.\r\n",
      "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\r\n",
      "jaxlib 0.4.33 requires scipy>=1.10, but you have scipy 1.9.3 which is incompatible.\r\n",
      "kaggle-environments 1.16.11 requires scipy>=1.11.2, but you have scipy 1.9.3 which is incompatible.\r\n",
      "langchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.23.5 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.23.5 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.23.5 which is incompatible.\r\n",
      "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "plotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\r\n",
      "pyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.23.5 which is incompatible.\r\n",
      "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\r\n",
      "stumpy 1.13.0 requires scipy>=1.10, but you have scipy 1.9.3 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\r\n",
      "woodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\r\n",
      "woodwork 0.31.0 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\r\n",
      "xarray 2024.11.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed numpy-1.23.5 scikit-image-0.19.3 scipy-1.9.3\r\n",
      "2025-03-22 06:12:10,608 I 18 <ipython-input-1-4a74d6249820>:292] Using device: cuda\n",
      "2025-03-22 06:12:10,609 D 18 <ipython-input-1-4a74d6249820>:300] Transform pipeline initialized\n",
      "2025-03-22 06:12:10,670 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0000.png with size (1000, 750)\n",
      "2025-03-22 06:12:10,701 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0001.png with size (1000, 750)\n",
      "2025-03-22 06:12:10,732 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0002.png with size (1000, 750)\n",
      "2025-03-22 06:12:10,767 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0003.png with size (1000, 750)\n",
      "2025-03-22 06:12:10,795 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0004.png with size (1000, 750)\n",
      "2025-03-22 06:12:10,826 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0005.png with size (1000, 750)\n",
      "2025-03-22 06:12:10,853 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0006.png with size (1000, 750)\n",
      "2025-03-22 06:12:10,886 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0007.png with size (1000, 750)\n",
      "2025-03-22 06:12:10,918 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0008.png with size (1000, 750)\n",
      "2025-03-22 06:12:10,948 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0009.png with size (1000, 750)\n",
      "2025-03-22 06:12:10,980 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0010.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,007 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0011.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,036 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0012.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,067 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0013.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,099 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0014.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,130 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0015.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,176 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0016.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,208 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0017.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,265 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0018.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,289 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0019.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,315 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0020.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,353 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0021.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,377 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0022.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,412 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0023.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,434 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0024.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,457 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0025.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,488 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0026.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,515 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0027.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,556 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0028.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,587 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0029.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,614 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0030.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,646 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0031.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,681 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0032.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,715 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0033.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,750 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0034.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,774 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0035.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,807 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0036.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,837 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0037.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,867 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0038.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,904 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0039.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,937 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0040.png with size (1000, 750)\n",
      "2025-03-22 06:12:11,970 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0041.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,000 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0042.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,024 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0043.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,053 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0044.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,085 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0045.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,116 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0046.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,154 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0047.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,179 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0048.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,206 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0049.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,240 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0050.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,268 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0051.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,298 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0052.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,331 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0053.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,359 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0054.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,385 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0055.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,416 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0056.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,451 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0057.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,483 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0058.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,514 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0059.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,565 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0060.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,602 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0061.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,645 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0062.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,683 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0063.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,718 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0064.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,750 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0065.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,792 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0066.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,820 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0067.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,872 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0068.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,902 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0069.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,935 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0070.png with size (1000, 750)\n",
      "2025-03-22 06:12:12,975 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0071.png with size (1000, 750)\n",
      "2025-03-22 06:12:13,008 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0072.png with size (1000, 750)\n",
      "2025-03-22 06:12:13,046 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0073.png with size (1000, 750)\n",
      "2025-03-22 06:12:13,072 D 18 <ipython-input-1-4a74d6249820>:44] Loaded 0074.png with size (1000, 750)\n",
      "2025-03-22 06:12:13,072 D 18 <ipython-input-1-4a74d6249820>:50] Initialized dataset with 75 valid files (out of 75 expected)\n",
      "2025-03-22 06:12:13,074 I 18 <ipython-input-1-4a74d6249820>:310] Checking test dataset\n",
      "2025-03-22 06:12:13,074 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0000.png\n",
      "2025-03-22 06:12:13,114 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0000.png\n",
      "2025-03-22 06:12:13,206 I 18 <ipython-input-1-4a74d6249820>:314] Successfully loaded 0000.png with original size (1000, 750)\n",
      "2025-03-22 06:12:13,206 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0001.png\n",
      "2025-03-22 06:12:13,226 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0001.png\n",
      "2025-03-22 06:12:13,238 I 18 <ipython-input-1-4a74d6249820>:314] Successfully loaded 0001.png with original size (1000, 750)\n",
      "2025-03-22 06:12:13,238 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0002.png\n",
      "2025-03-22 06:12:13,259 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0002.png\n",
      "2025-03-22 06:12:13,266 I 18 <ipython-input-1-4a74d6249820>:314] Successfully loaded 0002.png with original size (1000, 750)\n",
      "2025-03-22 06:12:13,266 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0003.png\n",
      "2025-03-22 06:12:13,287 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0003.png\n",
      "2025-03-22 06:12:13,296 I 18 <ipython-input-1-4a74d6249820>:314] Successfully loaded 0003.png with original size (1000, 750)\n",
      "2025-03-22 06:12:13,296 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0004.png\n",
      "2025-03-22 06:12:13,321 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0004.png\n",
      "2025-03-22 06:12:13,329 I 18 <ipython-input-1-4a74d6249820>:314] Successfully loaded 0004.png with original size (1000, 750)\n",
      "2025-03-22 06:12:13,330 I 18 <ipython-input-1-4a74d6249820>:321] DataLoader initialized\n",
      "2025-03-22 06:12:13,348 D 18 <ipython-input-1-4a74d6249820>:97] Initialized LocalSelfAttention with dim=32, num_heads=4, window_size=8\n",
      "2025-03-22 06:12:13,349 D 18 <ipython-input-1-4a74d6249820>:137] Initialized SMLP with dim=32\n",
      "2025-03-22 06:12:13,351 D 18 <ipython-input-1-4a74d6249820>:157] Initialized HomoBlock with dim=32, num_heads=4, window_size=8\n",
      "2025-03-22 06:12:13,353 D 18 <ipython-input-1-4a74d6249820>:97] Initialized LocalSelfAttention with dim=64, num_heads=4, window_size=8\n",
      "2025-03-22 06:12:13,355 D 18 <ipython-input-1-4a74d6249820>:137] Initialized SMLP with dim=64\n",
      "2025-03-22 06:12:13,355 D 18 <ipython-input-1-4a74d6249820>:157] Initialized HomoBlock with dim=64, num_heads=4, window_size=8\n",
      "2025-03-22 06:12:13,358 D 18 <ipython-input-1-4a74d6249820>:97] Initialized LocalSelfAttention with dim=128, num_heads=4, window_size=8\n",
      "2025-03-22 06:12:13,360 D 18 <ipython-input-1-4a74d6249820>:137] Initialized SMLP with dim=128\n",
      "2025-03-22 06:12:13,361 D 18 <ipython-input-1-4a74d6249820>:157] Initialized HomoBlock with dim=128, num_heads=4, window_size=8\n",
      "2025-03-22 06:12:13,364 D 18 <ipython-input-1-4a74d6249820>:97] Initialized LocalSelfAttention with dim=64, num_heads=4, window_size=8\n",
      "2025-03-22 06:12:13,365 D 18 <ipython-input-1-4a74d6249820>:137] Initialized SMLP with dim=64\n",
      "2025-03-22 06:12:13,366 D 18 <ipython-input-1-4a74d6249820>:157] Initialized HomoBlock with dim=64, num_heads=4, window_size=8\n",
      "2025-03-22 06:12:13,368 D 18 <ipython-input-1-4a74d6249820>:97] Initialized LocalSelfAttention with dim=32, num_heads=4, window_size=8\n",
      "2025-03-22 06:12:13,370 D 18 <ipython-input-1-4a74d6249820>:137] Initialized SMLP with dim=32\n",
      "2025-03-22 06:12:13,371 D 18 <ipython-input-1-4a74d6249820>:157] Initialized HomoBlock with dim=32, num_heads=4, window_size=8\n",
      "2025-03-22 06:12:13,372 D 18 <ipython-input-1-4a74d6249820>:196] Initialized HomoFormer with in_channels=3, out_channels=3, dim=32, num_levels=2\n",
      "2025-03-22 06:12:13,616 I 18 <ipython-input-1-4a74d6249820>:326] Model initialized\n",
      "2025-03-22 06:12:13,662 I 18 <ipython-input-1-4a74d6249820>:344] Loaded model weights from: /kaggle/input/imageshadowremoval/pytorch/default/1/shadow_removal_model.pth\n",
      "2025-03-22 06:12:13,663 I 18 <ipython-input-1-4a74d6249820>:349] Starting test phase\n",
      "2025-03-22 06:12:13,670 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0000.png\n",
      "2025-03-22 06:12:13,694 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0000.png\n",
      "2025-03-22 06:12:13,704 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0001.png\n",
      "2025-03-22 06:12:13,720 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0001.png\n",
      "2025-03-22 06:12:13,729 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0002.png\n",
      "2025-03-22 06:12:13,755 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0002.png\n",
      "2025-03-22 06:12:13,761 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0003.png\n",
      "2025-03-22 06:12:13,781 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0003.png\n",
      "2025-03-22 06:12:13,814 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 1/19\n",
      "2025-03-22 06:12:13,815 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-4a74d6249820>:336: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-22 06:12:14,622 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:14,623 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:14,670 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:14,892 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:14,894 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:14,918 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:14,920 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:14,922 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:14,923 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:14,924 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:14,927 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:14,928 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:14,929 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:14,930 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:14,933 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:14,934 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:14,934 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:14,937 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:14,938 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:14,939 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:14,940 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:14,941 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:14,996 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:14,997 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,000 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,001 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,002 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,003 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,003 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:15,005 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,006 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,012 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,012 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,014 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,015 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,059 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:15,084 D 18 <ipython-input-1-4a74d6249820>:360] Batch 1: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:15,085 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:15,086 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0000_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:15,123 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0000_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:15,124 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0001_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:15,151 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0001_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:15,152 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0002_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:15,183 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0002_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:15,184 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0003_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:15,214 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0003_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:15,215 I 18 <ipython-input-1-4a74d6249820>:363] Processed 4 images so far\n",
      "2025-03-22 06:12:15,216 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0004.png\n",
      "2025-03-22 06:12:15,235 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0004.png\n",
      "2025-03-22 06:12:15,242 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0005.png\n",
      "2025-03-22 06:12:15,261 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0005.png\n",
      "2025-03-22 06:12:15,268 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0006.png\n",
      "2025-03-22 06:12:15,286 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0006.png\n",
      "2025-03-22 06:12:15,292 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0007.png\n",
      "2025-03-22 06:12:15,312 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0007.png\n",
      "2025-03-22 06:12:15,318 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 2/19\n",
      "2025-03-22 06:12:15,319 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:15,320 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:15,321 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,322 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,327 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,329 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,330 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,331 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,332 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:15,333 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,334 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,337 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,338 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,339 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,340 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,341 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:15,342 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,343 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,345 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,346 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,347 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,348 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,349 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:15,350 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,351 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,354 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,355 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,356 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,357 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,358 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:15,359 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,360 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,365 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,366 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,367 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,368 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,369 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:15,370 D 18 <ipython-input-1-4a74d6249820>:360] Batch 2: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:15,371 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:15,372 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0004_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:15,403 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0004_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:15,404 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0005_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:15,433 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0005_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:15,434 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0006_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:15,463 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0006_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:15,464 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0007_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:15,495 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0007_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:15,496 I 18 <ipython-input-1-4a74d6249820>:363] Processed 8 images so far\n",
      "2025-03-22 06:12:15,497 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0008.png\n",
      "2025-03-22 06:12:15,518 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0008.png\n",
      "2025-03-22 06:12:15,524 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0009.png\n",
      "2025-03-22 06:12:15,543 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0009.png\n",
      "2025-03-22 06:12:15,549 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0010.png\n",
      "2025-03-22 06:12:15,570 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0010.png\n",
      "2025-03-22 06:12:15,575 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0011.png\n",
      "2025-03-22 06:12:15,597 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0011.png\n",
      "2025-03-22 06:12:15,603 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 3/19\n",
      "2025-03-22 06:12:15,604 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:15,604 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:15,605 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,606 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,612 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,613 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,614 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,614 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,616 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:15,616 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,617 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,620 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,621 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,622 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,623 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,624 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:15,625 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,626 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,628 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,629 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,630 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,631 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,632 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:15,633 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,634 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,637 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,638 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,639 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,641 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,642 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:15,644 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,645 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,651 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,652 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,654 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,655 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,657 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:15,658 D 18 <ipython-input-1-4a74d6249820>:360] Batch 3: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:15,659 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:15,661 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0008_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:15,691 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0008_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:15,692 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0009_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:15,721 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0009_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:15,722 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0010_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:15,752 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0010_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:15,753 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0011_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:15,784 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0011_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:15,784 I 18 <ipython-input-1-4a74d6249820>:363] Processed 12 images so far\n",
      "2025-03-22 06:12:15,785 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0012.png\n",
      "2025-03-22 06:12:15,805 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0012.png\n",
      "2025-03-22 06:12:15,811 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0013.png\n",
      "2025-03-22 06:12:15,831 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0013.png\n",
      "2025-03-22 06:12:15,837 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0014.png\n",
      "2025-03-22 06:12:15,857 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0014.png\n",
      "2025-03-22 06:12:15,863 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0015.png\n",
      "2025-03-22 06:12:15,883 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0015.png\n",
      "2025-03-22 06:12:15,890 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 4/19\n",
      "2025-03-22 06:12:15,890 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:15,891 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:15,892 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,893 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,898 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,899 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,900 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,901 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,902 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:15,903 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,904 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,906 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,907 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,909 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,910 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,911 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:15,911 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,913 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,915 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,915 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,917 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,917 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:15,918 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:15,919 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,920 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,923 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,924 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,925 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,926 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:15,927 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:15,929 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,930 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,935 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,936 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,937 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,938 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:15,939 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:15,940 D 18 <ipython-input-1-4a74d6249820>:360] Batch 4: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:15,941 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:15,942 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0012_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:15,973 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0012_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:15,975 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0013_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:16,007 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0013_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:16,008 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0014_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:16,036 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0014_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:16,037 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0015_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:16,068 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0015_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:16,068 I 18 <ipython-input-1-4a74d6249820>:363] Processed 16 images so far\n",
      "2025-03-22 06:12:16,069 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0016.png\n",
      "2025-03-22 06:12:16,089 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0016.png\n",
      "2025-03-22 06:12:16,095 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0017.png\n",
      "2025-03-22 06:12:16,115 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0017.png\n",
      "2025-03-22 06:12:16,121 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0018.png\n",
      "2025-03-22 06:12:16,147 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0018.png\n",
      "2025-03-22 06:12:16,152 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0019.png\n",
      "2025-03-22 06:12:16,170 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0019.png\n",
      "2025-03-22 06:12:16,176 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 5/19\n",
      "2025-03-22 06:12:16,177 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:16,178 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:16,179 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,181 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,186 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,187 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,188 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,189 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,190 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:16,192 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,192 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,195 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,196 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,198 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,199 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,200 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:16,200 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,201 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,203 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,204 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,206 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,207 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,208 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:16,209 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,210 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,212 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,213 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,214 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,215 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,216 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:16,217 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,218 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,224 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,225 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,226 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,227 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,228 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:16,229 D 18 <ipython-input-1-4a74d6249820>:360] Batch 5: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:16,230 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:16,231 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0016_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:16,259 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0016_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:16,260 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0017_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:16,290 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0017_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:16,291 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0018_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:16,320 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0018_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:16,321 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0019_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:16,347 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0019_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:16,348 I 18 <ipython-input-1-4a74d6249820>:363] Processed 20 images so far\n",
      "2025-03-22 06:12:16,349 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0020.png\n",
      "2025-03-22 06:12:16,366 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0020.png\n",
      "2025-03-22 06:12:16,373 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0021.png\n",
      "2025-03-22 06:12:16,393 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0021.png\n",
      "2025-03-22 06:12:16,399 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0022.png\n",
      "2025-03-22 06:12:16,416 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0022.png\n",
      "2025-03-22 06:12:16,422 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0023.png\n",
      "2025-03-22 06:12:16,441 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0023.png\n",
      "2025-03-22 06:12:16,448 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 6/19\n",
      "2025-03-22 06:12:16,449 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:16,450 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:16,451 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,452 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,458 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,459 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,460 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,461 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,462 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:16,462 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,463 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,466 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,467 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,469 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,470 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,470 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:16,471 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,473 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,475 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,475 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,477 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,478 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,478 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:16,480 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,480 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,483 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,484 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,485 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,487 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,487 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:16,489 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,490 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,495 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,496 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,497 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,498 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,499 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:16,500 D 18 <ipython-input-1-4a74d6249820>:360] Batch 6: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:16,501 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:16,503 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0020_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:16,530 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0020_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:16,531 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0021_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:16,560 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0021_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:16,562 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0022_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:16,588 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0022_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:16,589 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0023_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:16,619 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0023_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:16,619 I 18 <ipython-input-1-4a74d6249820>:363] Processed 24 images so far\n",
      "2025-03-22 06:12:16,620 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0024.png\n",
      "2025-03-22 06:12:16,637 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0024.png\n",
      "2025-03-22 06:12:16,643 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0025.png\n",
      "2025-03-22 06:12:16,660 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0025.png\n",
      "2025-03-22 06:12:16,665 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0026.png\n",
      "2025-03-22 06:12:16,686 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0026.png\n",
      "2025-03-22 06:12:16,691 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0027.png\n",
      "2025-03-22 06:12:16,712 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0027.png\n",
      "2025-03-22 06:12:16,718 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 7/19\n",
      "2025-03-22 06:12:16,719 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:16,720 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:16,721 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,722 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,727 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,728 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,729 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,730 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,732 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:16,732 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,733 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,736 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,737 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,738 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,739 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,740 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:16,741 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,742 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,744 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,745 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,746 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,747 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:16,748 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:16,749 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,750 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,752 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,753 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,754 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,755 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:16,756 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:16,757 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,758 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,764 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,765 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,766 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,767 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:16,768 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:16,769 D 18 <ipython-input-1-4a74d6249820>:360] Batch 7: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:16,770 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:16,771 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0024_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:16,799 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0024_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:16,800 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0025_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:16,829 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0025_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:16,830 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0026_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:16,857 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0026_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:16,858 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0027_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:16,888 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0027_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:16,889 I 18 <ipython-input-1-4a74d6249820>:363] Processed 28 images so far\n",
      "2025-03-22 06:12:16,890 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0028.png\n",
      "2025-03-22 06:12:16,910 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0028.png\n",
      "2025-03-22 06:12:16,915 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0029.png\n",
      "2025-03-22 06:12:16,940 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0029.png\n",
      "2025-03-22 06:12:16,946 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0030.png\n",
      "2025-03-22 06:12:16,964 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0030.png\n",
      "2025-03-22 06:12:16,970 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0031.png\n",
      "2025-03-22 06:12:16,990 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0031.png\n",
      "2025-03-22 06:12:16,996 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 8/19\n",
      "2025-03-22 06:12:16,997 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:16,998 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:16,999 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,000 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,005 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,006 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,007 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,008 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,009 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:17,009 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,011 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,014 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,015 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,016 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,017 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,018 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:17,019 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,020 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,022 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,023 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,024 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,025 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,026 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:17,027 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,029 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,031 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,032 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,033 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,034 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,035 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:17,036 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,037 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,042 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,043 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,044 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,045 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,046 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:17,047 D 18 <ipython-input-1-4a74d6249820>:360] Batch 8: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:17,048 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:17,049 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0028_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:17,079 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0028_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:17,080 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0029_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:17,108 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0029_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:17,109 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0030_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:17,137 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0030_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:17,138 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0031_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:17,168 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0031_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:17,168 I 18 <ipython-input-1-4a74d6249820>:363] Processed 32 images so far\n",
      "2025-03-22 06:12:17,169 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0032.png\n",
      "2025-03-22 06:12:17,189 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0032.png\n",
      "2025-03-22 06:12:17,196 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0033.png\n",
      "2025-03-22 06:12:17,215 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0033.png\n",
      "2025-03-22 06:12:17,221 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0034.png\n",
      "2025-03-22 06:12:17,241 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0034.png\n",
      "2025-03-22 06:12:17,247 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0035.png\n",
      "2025-03-22 06:12:17,265 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0035.png\n",
      "2025-03-22 06:12:17,271 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 9/19\n",
      "2025-03-22 06:12:17,272 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:17,273 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:17,273 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,275 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,281 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,282 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,283 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,284 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,285 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:17,286 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,287 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,290 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,291 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,292 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,293 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,294 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:17,295 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,296 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,298 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,299 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,300 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,301 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,302 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:17,303 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,304 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,307 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,308 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,309 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,310 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,310 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:17,312 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,313 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,318 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,319 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,320 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,321 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,322 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:17,323 D 18 <ipython-input-1-4a74d6249820>:360] Batch 9: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:17,324 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:17,325 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0032_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:17,354 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0032_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:17,355 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0033_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:17,380 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0033_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:17,382 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0034_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:17,411 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0034_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:17,412 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0035_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:17,441 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0035_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:17,441 I 18 <ipython-input-1-4a74d6249820>:363] Processed 36 images so far\n",
      "2025-03-22 06:12:17,442 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0036.png\n",
      "2025-03-22 06:12:17,463 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0036.png\n",
      "2025-03-22 06:12:17,469 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0037.png\n",
      "2025-03-22 06:12:17,490 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0037.png\n",
      "2025-03-22 06:12:17,496 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0038.png\n",
      "2025-03-22 06:12:17,516 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0038.png\n",
      "2025-03-22 06:12:17,522 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0039.png\n",
      "2025-03-22 06:12:17,542 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0039.png\n",
      "2025-03-22 06:12:17,548 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 10/19\n",
      "2025-03-22 06:12:17,549 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:17,550 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:17,550 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,551 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,557 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,558 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,559 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,559 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,561 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:17,561 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,563 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,566 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,567 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,568 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,569 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,570 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:17,570 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,572 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,573 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,574 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,576 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,577 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,577 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:17,578 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,579 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,582 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,583 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,584 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,585 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,586 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:17,587 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,588 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,594 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,595 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,596 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,597 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,598 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:17,599 D 18 <ipython-input-1-4a74d6249820>:360] Batch 10: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:17,600 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:17,601 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0036_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:17,631 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0036_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:17,632 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0037_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:17,664 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0037_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:17,665 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0038_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:17,694 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0038_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:17,695 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0039_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:17,726 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0039_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:17,727 I 18 <ipython-input-1-4a74d6249820>:363] Processed 40 images so far\n",
      "2025-03-22 06:12:17,728 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0040.png\n",
      "2025-03-22 06:12:17,747 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0040.png\n",
      "2025-03-22 06:12:17,753 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0041.png\n",
      "2025-03-22 06:12:17,773 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0041.png\n",
      "2025-03-22 06:12:17,779 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0042.png\n",
      "2025-03-22 06:12:17,804 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0042.png\n",
      "2025-03-22 06:12:17,810 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0043.png\n",
      "2025-03-22 06:12:17,826 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0043.png\n",
      "2025-03-22 06:12:17,832 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 11/19\n",
      "2025-03-22 06:12:17,833 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:17,834 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:17,834 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,835 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,841 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,842 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,843 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,844 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,845 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:17,846 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,846 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,849 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,851 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,852 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,853 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,854 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:17,855 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,856 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,858 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,859 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,860 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,861 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:17,862 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:17,863 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,864 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,867 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,868 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,869 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,870 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:17,871 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:17,872 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,873 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,878 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,879 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,880 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,881 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:17,882 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:17,883 D 18 <ipython-input-1-4a74d6249820>:360] Batch 11: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:17,884 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:17,885 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0040_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:17,915 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0040_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:17,916 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0041_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:17,946 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0041_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:17,947 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0042_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:17,977 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0042_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:17,978 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0043_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:18,005 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0043_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:18,005 I 18 <ipython-input-1-4a74d6249820>:363] Processed 44 images so far\n",
      "2025-03-22 06:12:18,006 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0044.png\n",
      "2025-03-22 06:12:18,026 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0044.png\n",
      "2025-03-22 06:12:18,032 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0045.png\n",
      "2025-03-22 06:12:18,052 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0045.png\n",
      "2025-03-22 06:12:18,058 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0046.png\n",
      "2025-03-22 06:12:18,078 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0046.png\n",
      "2025-03-22 06:12:18,083 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0047.png\n",
      "2025-03-22 06:12:18,102 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0047.png\n",
      "2025-03-22 06:12:18,108 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 12/19\n",
      "2025-03-22 06:12:18,109 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:18,110 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:18,111 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,112 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,117 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,118 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,119 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,120 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,122 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:18,122 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,123 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,126 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,127 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,128 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,129 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,130 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:18,131 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,132 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,134 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,135 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,136 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,137 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,138 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:18,139 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,140 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,143 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,144 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,145 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,146 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,146 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:18,148 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,149 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,154 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,155 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,156 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,157 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,158 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:18,159 D 18 <ipython-input-1-4a74d6249820>:360] Batch 12: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:18,160 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:18,161 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0044_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:18,192 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0044_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:18,193 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0045_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:18,222 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0045_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:18,223 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0046_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:18,252 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0046_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:18,253 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0047_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:18,282 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0047_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:18,282 I 18 <ipython-input-1-4a74d6249820>:363] Processed 48 images so far\n",
      "2025-03-22 06:12:18,283 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0048.png\n",
      "2025-03-22 06:12:18,300 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0048.png\n",
      "2025-03-22 06:12:18,306 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0049.png\n",
      "2025-03-22 06:12:18,326 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0049.png\n",
      "2025-03-22 06:12:18,332 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0050.png\n",
      "2025-03-22 06:12:18,352 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0050.png\n",
      "2025-03-22 06:12:18,358 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0051.png\n",
      "2025-03-22 06:12:18,378 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0051.png\n",
      "2025-03-22 06:12:18,384 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 13/19\n",
      "2025-03-22 06:12:18,385 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:18,386 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:18,387 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,388 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,393 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,394 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,395 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,396 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,397 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:18,398 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,399 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,402 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,403 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,404 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,405 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,406 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:18,407 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,408 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,410 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,411 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,412 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,413 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,413 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:18,415 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,415 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,418 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,419 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,420 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,421 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,422 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:18,423 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,424 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,429 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,430 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,431 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,432 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,433 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:18,434 D 18 <ipython-input-1-4a74d6249820>:360] Batch 13: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:18,435 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:18,437 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0048_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:18,465 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0048_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:18,466 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0049_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:18,495 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0049_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:18,497 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0050_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:18,525 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0050_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:18,526 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0051_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:18,560 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0051_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:18,560 I 18 <ipython-input-1-4a74d6249820>:363] Processed 52 images so far\n",
      "2025-03-22 06:12:18,561 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0052.png\n",
      "2025-03-22 06:12:18,581 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0052.png\n",
      "2025-03-22 06:12:18,587 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0053.png\n",
      "2025-03-22 06:12:18,606 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0053.png\n",
      "2025-03-22 06:12:18,613 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0054.png\n",
      "2025-03-22 06:12:18,629 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0054.png\n",
      "2025-03-22 06:12:18,636 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0055.png\n",
      "2025-03-22 06:12:18,655 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0055.png\n",
      "2025-03-22 06:12:18,661 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 14/19\n",
      "2025-03-22 06:12:18,662 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:18,663 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:18,664 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,665 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,670 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,671 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,672 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,673 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,674 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:18,675 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,675 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,679 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,680 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,681 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,682 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,684 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:18,685 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,686 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,688 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,689 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,691 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,692 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,693 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:18,695 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,696 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,699 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,700 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,701 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,701 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,702 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:18,704 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,705 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,710 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,712 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,712 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,713 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,714 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:18,716 D 18 <ipython-input-1-4a74d6249820>:360] Batch 14: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:18,717 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:18,719 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0052_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:18,752 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0052_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:18,754 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0053_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:18,788 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0053_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:18,789 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0054_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:18,815 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0054_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:18,816 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0055_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:18,846 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0055_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:18,847 I 18 <ipython-input-1-4a74d6249820>:363] Processed 56 images so far\n",
      "2025-03-22 06:12:18,847 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0056.png\n",
      "2025-03-22 06:12:18,868 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0056.png\n",
      "2025-03-22 06:12:18,874 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0057.png\n",
      "2025-03-22 06:12:18,895 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0057.png\n",
      "2025-03-22 06:12:18,901 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0058.png\n",
      "2025-03-22 06:12:18,921 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0058.png\n",
      "2025-03-22 06:12:18,927 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0059.png\n",
      "2025-03-22 06:12:18,947 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0059.png\n",
      "2025-03-22 06:12:18,953 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 15/19\n",
      "2025-03-22 06:12:18,954 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:18,955 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:18,955 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,956 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,962 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,963 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,963 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,964 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,965 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:18,966 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,967 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,970 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,971 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,972 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,973 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,974 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:18,974 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,976 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,978 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,979 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,980 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,981 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:18,982 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:18,983 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,984 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,986 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,987 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,988 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,989 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:18,990 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:18,991 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,992 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,997 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:18,998 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,000 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,000 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,002 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:19,003 D 18 <ipython-input-1-4a74d6249820>:360] Batch 15: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:19,005 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:19,006 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0056_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,037 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0056_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,039 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0057_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,068 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0057_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,069 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0058_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,103 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0058_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,104 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0059_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,133 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0059_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,134 I 18 <ipython-input-1-4a74d6249820>:363] Processed 60 images so far\n",
      "2025-03-22 06:12:19,135 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0060.png\n",
      "2025-03-22 06:12:19,155 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0060.png\n",
      "2025-03-22 06:12:19,161 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0061.png\n",
      "2025-03-22 06:12:19,181 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0061.png\n",
      "2025-03-22 06:12:19,187 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0062.png\n",
      "2025-03-22 06:12:19,207 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0062.png\n",
      "2025-03-22 06:12:19,213 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0063.png\n",
      "2025-03-22 06:12:19,234 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0063.png\n",
      "2025-03-22 06:12:19,241 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 16/19\n",
      "2025-03-22 06:12:19,241 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:19,242 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:19,243 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,245 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,250 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,251 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,252 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,253 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,254 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:19,255 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,256 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,259 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,260 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,261 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,262 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,263 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:19,264 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,265 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,267 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,268 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,269 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,270 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,271 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:19,272 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,273 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,275 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,276 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,278 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,279 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,279 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:19,281 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,281 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,287 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,288 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,289 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,290 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,291 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:19,292 D 18 <ipython-input-1-4a74d6249820>:360] Batch 16: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:19,293 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:19,294 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0060_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,324 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0060_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,326 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0061_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,355 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0061_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,356 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0062_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,385 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0062_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,386 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0063_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,417 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0063_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,418 I 18 <ipython-input-1-4a74d6249820>:363] Processed 64 images so far\n",
      "2025-03-22 06:12:19,418 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0064.png\n",
      "2025-03-22 06:12:19,438 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0064.png\n",
      "2025-03-22 06:12:19,444 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0065.png\n",
      "2025-03-22 06:12:19,465 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0065.png\n",
      "2025-03-22 06:12:19,470 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0066.png\n",
      "2025-03-22 06:12:19,491 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0066.png\n",
      "2025-03-22 06:12:19,497 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0067.png\n",
      "2025-03-22 06:12:19,514 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0067.png\n",
      "2025-03-22 06:12:19,520 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 17/19\n",
      "2025-03-22 06:12:19,521 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:19,522 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:19,523 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,523 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,529 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,530 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,531 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,532 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,533 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:19,534 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,535 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,538 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,539 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,540 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,541 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,542 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:19,543 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,544 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,546 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,547 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,548 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,549 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,550 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:19,551 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,552 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,554 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,556 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,557 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,558 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,558 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:19,560 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,561 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,566 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,567 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,568 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,569 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,570 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:19,571 D 18 <ipython-input-1-4a74d6249820>:360] Batch 17: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:19,572 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:19,573 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0064_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,603 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0064_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,604 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0065_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,633 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0065_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,634 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0066_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,666 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0066_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,667 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0067_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,696 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0067_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,697 I 18 <ipython-input-1-4a74d6249820>:363] Processed 68 images so far\n",
      "2025-03-22 06:12:19,697 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0068.png\n",
      "2025-03-22 06:12:19,718 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0068.png\n",
      "2025-03-22 06:12:19,724 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0069.png\n",
      "2025-03-22 06:12:19,744 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0069.png\n",
      "2025-03-22 06:12:19,749 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0070.png\n",
      "2025-03-22 06:12:19,771 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0070.png\n",
      "2025-03-22 06:12:19,776 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0071.png\n",
      "2025-03-22 06:12:19,795 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0071.png\n",
      "2025-03-22 06:12:19,801 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 18/19\n",
      "2025-03-22 06:12:19,802 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:19,803 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:19,803 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,805 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,810 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,811 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,812 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,813 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,815 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:19,815 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,816 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,819 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,820 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,821 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,821 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,823 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:19,823 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,825 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,827 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,828 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,829 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,830 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 32, 32, 128])\n",
      "2025-03-22 06:12:19,831 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:19,832 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,833 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,836 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,837 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,838 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,839 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 64, 64, 64])\n",
      "2025-03-22 06:12:19,839 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:19,841 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,842 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,847 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,848 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,849 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,850 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([4, 128, 128, 32])\n",
      "2025-03-22 06:12:19,851 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([4, 3, 128, 128])\n",
      "2025-03-22 06:12:19,852 D 18 <ipython-input-1-4a74d6249820>:360] Batch 18: output.shape=torch.Size([4, 3, 128, 128]), len(filenames)=4, len(original_sizes)=4\n",
      "2025-03-22 06:12:19,853 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:19,854 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0068_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,885 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0068_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,886 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0069_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,917 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0069_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,918 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0070_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,948 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0070_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,949 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0071_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:19,978 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0071_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:19,978 I 18 <ipython-input-1-4a74d6249820>:363] Processed 72 images so far\n",
      "2025-03-22 06:12:19,979 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0072.png\n",
      "2025-03-22 06:12:19,999 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0072.png\n",
      "2025-03-22 06:12:20,005 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0073.png\n",
      "2025-03-22 06:12:20,025 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0073.png\n",
      "2025-03-22 06:12:20,031 D 18 <ipython-input-1-4a74d6249820>:62] Attempting to load shadow image: /kaggle/input/shadowtest/0074.png\n",
      "2025-03-22 06:12:20,047 D 18 <ipython-input-1-4a74d6249820>:74] Loaded shadow image: 0074.png\n",
      "2025-03-22 06:12:20,053 D 18 <ipython-input-1-4a74d6249820>:356] Processing test batch 19/19\n",
      "2025-03-22 06:12:20,053 D 18 <ipython-input-1-4a74d6249820>:200] HomoFormer input shape: torch.Size([3, 3, 128, 128])\n",
      "2025-03-22 06:12:20,059 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 1\n",
      "2025-03-22 06:12:20,060 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([3, 128, 128, 32])\n",
      "2025-03-22 06:12:20,061 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([3, 128, 128, 32])\n",
      "2025-03-22 06:12:20,065 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([3, 128, 128, 32])\n",
      "2025-03-22 06:12:20,066 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([3, 128, 128, 32])\n",
      "2025-03-22 06:12:20,067 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([3, 128, 128, 32])\n",
      "2025-03-22 06:12:20,068 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([3, 128, 128, 32])\n",
      "2025-03-22 06:12:20,070 D 18 <ipython-input-1-4a74d6249820>:207] Downsampling level 2\n",
      "2025-03-22 06:12:20,071 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([3, 64, 64, 64])\n",
      "2025-03-22 06:12:20,072 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([3, 64, 64, 64])\n",
      "2025-03-22 06:12:20,074 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([3, 64, 64, 64])\n",
      "2025-03-22 06:12:20,075 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([3, 64, 64, 64])\n",
      "2025-03-22 06:12:20,077 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([3, 64, 64, 64])\n",
      "2025-03-22 06:12:20,078 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([3, 64, 64, 64])\n",
      "2025-03-22 06:12:20,080 D 18 <ipython-input-1-4a74d6249820>:215] Processing bottleneck\n",
      "2025-03-22 06:12:20,080 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([3, 32, 32, 128])\n",
      "2025-03-22 06:12:20,081 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([3, 32, 32, 128])\n",
      "2025-03-22 06:12:20,083 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([3, 32, 32, 128])\n",
      "2025-03-22 06:12:20,084 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([3, 32, 32, 128])\n",
      "2025-03-22 06:12:20,086 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([3, 32, 32, 128])\n",
      "2025-03-22 06:12:20,086 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([3, 32, 32, 128])\n",
      "2025-03-22 06:12:20,087 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 1\n",
      "2025-03-22 06:12:20,090 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([3, 64, 64, 64])\n",
      "2025-03-22 06:12:20,091 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([3, 64, 64, 64])\n",
      "2025-03-22 06:12:20,093 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([3, 64, 64, 64])\n",
      "2025-03-22 06:12:20,094 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([3, 64, 64, 64])\n",
      "2025-03-22 06:12:20,095 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([3, 64, 64, 64])\n",
      "2025-03-22 06:12:20,096 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([3, 64, 64, 64])\n",
      "2025-03-22 06:12:20,098 D 18 <ipython-input-1-4a74d6249820>:219] Upsampling level 2\n",
      "2025-03-22 06:12:20,099 D 18 <ipython-input-1-4a74d6249820>:161] HomoBlock input shape: torch.Size([3, 128, 128, 32])\n",
      "2025-03-22 06:12:20,099 D 18 <ipython-input-1-4a74d6249820>:102] LocalSelfAttention input shape: torch.Size([3, 128, 128, 32])\n",
      "2025-03-22 06:12:20,104 D 18 <ipython-input-1-4a74d6249820>:122] LocalSelfAttention output shape: torch.Size([3, 128, 128, 32])\n",
      "2025-03-22 06:12:20,105 D 18 <ipython-input-1-4a74d6249820>:141] SMLP input shape: torch.Size([3, 128, 128, 32])\n",
      "2025-03-22 06:12:20,105 D 18 <ipython-input-1-4a74d6249820>:143] SMLP output shape: torch.Size([3, 128, 128, 32])\n",
      "2025-03-22 06:12:20,107 D 18 <ipython-input-1-4a74d6249820>:164] HomoBlock output shape: torch.Size([3, 128, 128, 32])\n",
      "2025-03-22 06:12:20,109 D 18 <ipython-input-1-4a74d6249820>:230] HomoFormer output shape: torch.Size([3, 3, 128, 128])\n",
      "2025-03-22 06:12:20,110 D 18 <ipython-input-1-4a74d6249820>:360] Batch 19: output.shape=torch.Size([3, 3, 128, 128]), len(filenames)=3, len(original_sizes)=3\n",
      "2025-03-22 06:12:20,110 D 18 <ipython-input-1-4a74d6249820>:240] Created output directory: /kaggle/working/test_output\n",
      "2025-03-22 06:12:20,111 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0072_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:20,142 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0072_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:20,143 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0073_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:20,174 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0073_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:20,175 D 18 <ipython-input-1-4a74d6249820>:259] Resizing 0074_out.png to original size (1000, 750)\n",
      "2025-03-22 06:12:20,200 I 18 <ipython-input-1-4a74d6249820>:262] Saved output image: /kaggle/working/test_output/0074_out.png with resolution (1000, 750)\n",
      "2025-03-22 06:12:20,201 I 18 <ipython-input-1-4a74d6249820>:363] Processed 75 images so far\n",
      "2025-03-22 06:12:20,202 I 18 <ipython-input-1-4a74d6249820>:369] Test phase completed\n",
      "2025-03-22 06:12:20,203 I 18 <ipython-input-1-4a74d6249820>:373] Number of output images generated: 75\n",
      "2025-03-22 06:12:33,312 I 18 <ipython-input-1-4a74d6249820>:383] Created submission ZIP at: /kaggle/working/submission.zip\n",
      "2025-03-22 06:12:33,315 I 18 <ipython-input-1-4a74d6249820>:388] Contents of submission.zip: ['0038_out.png', '0004_out.png', '0023_out.png', '0011_out.png', '0056_out.png', '0036_out.png', '0021_out.png', '0026_out.png', '0068_out.png', '0025_out.png', '0042_out.png', '0032_out.png', '0031_out.png', '0053_out.png', '0057_out.png', '0016_out.png', '0043_out.png', '0066_out.png', '0067_out.png', '0060_out.png', '0037_out.png', '0063_out.png', '0019_out.png', '0061_out.png', '0046_out.png', '0018_out.png', '0049_out.png', '0040_out.png', '0033_out.png', '0027_out.png', '0034_out.png', '0072_out.png', '0041_out.png', '0006_out.png', '0045_out.png', '0035_out.png', '0074_out.png', '0009_out.png', '0020_out.png', '0030_out.png', '0014_out.png', '0044_out.png', '0050_out.png', '0024_out.png', '0059_out.png', '0058_out.png', '0013_out.png', '0000_out.png', '0070_out.png', '0029_out.png', '0064_out.png', '0010_out.png', '0048_out.png', '0003_out.png', '0015_out.png', '0002_out.png', '0028_out.png', '0008_out.png', '0012_out.png', '0007_out.png', '0055_out.png', '0069_out.png', '0054_out.png', '0062_out.png', '0071_out.png', '0017_out.png', '0005_out.png', '0052_out.png', '0022_out.png', '0073_out.png', '0039_out.png', '0051_out.png', '0065_out.png', '0001_out.png', '0047_out.png']\n",
      "2025-03-22 06:12:33,315 I 18 <ipython-input-1-4a74d6249820>:390] Number of .png files in submission.zip: 75\n",
      "Deshadowed test images saved in: /kaggle/working/test_output\n",
      "Submission ZIP file created at: /kaggle/working/submission.zip\n",
      "Average runtime per image [s]: 0.09\n",
      "2025-03-22 06:12:33,316 I 18 <ipython-input-1-4a74d6249820>:404] Script execution completed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import zipfile  # For creating ZIP file\n",
    "\n",
    "# Set up detailed logging with immediate flushing\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "logging.getLogger().handlers[0].setStream(sys.stdout)\n",
    "logging.getLogger().handlers[0].flush = sys.stdout.flush\n",
    "\n",
    "# Define Dataset Class\n",
    "class ShadowRemovalDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Assuming test dataset has images named 0000.png to 0074.png\n",
    "        self.indices = range(0, 75)  # Adjust this range if your dataset has a different naming scheme\n",
    "        self.image_files = [f\"{str(i).zfill(4)}.png\" for i in self.indices]\n",
    "        \n",
    "        # Store original sizes for all images\n",
    "        self.original_sizes = []\n",
    "        self.valid_files = []\n",
    "        for fname in self.image_files:\n",
    "            fpath = os.path.join(self.root_dir, fname)\n",
    "            if os.path.exists(fpath):\n",
    "                img = cv2.imread(fpath)\n",
    "                if img is not None:\n",
    "                    self.valid_files.append(fname)\n",
    "                    self.original_sizes.append((img.shape[1], img.shape[0]))  # (width, height)\n",
    "                    logging.debug(f\"Loaded {fname} with size {self.original_sizes[-1]}\")\n",
    "                else:\n",
    "                    logging.warning(f\"Failed to load image for size check: {fpath}\")\n",
    "            else:\n",
    "                logging.warning(f\"File not found: {fpath}\")\n",
    "        \n",
    "        logging.debug(f\"Initialized dataset with {len(self.valid_files)} valid files (out of {len(self.image_files)} expected)\")\n",
    "        if len(self.valid_files) != 75:\n",
    "            logging.warning(f\"Expected 75 files for test dataset, but found {len(self.valid_files)}. Proceeding with available files.\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.valid_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            shadow_filename = self.valid_files[idx]\n",
    "            shadow_path = os.path.join(self.root_dir, shadow_filename)\n",
    "            \n",
    "            logging.debug(f\"Attempting to load shadow image: {shadow_path}\")\n",
    "            \n",
    "            if not os.path.exists(shadow_path):\n",
    "                logging.error(f\"Shadow image not found: {shadow_path}\")\n",
    "                raise ValueError(f\"Shadow image not found: {shadow_path}\")\n",
    "            \n",
    "            shadow_img = cv2.imread(shadow_path)\n",
    "            if shadow_img is None:\n",
    "                logging.error(f\"Failed to load shadow image: {shadow_filename}\")\n",
    "                raise ValueError(f\"Failed to load shadow image: {shadow_filename}\")\n",
    "            \n",
    "            shadow_img = cv2.cvtColor(shadow_img, cv2.COLOR_BGR2RGB)\n",
    "            logging.debug(f\"Loaded shadow image: {shadow_filename}\")\n",
    "            \n",
    "            if self.transform:\n",
    "                shadow_img = self.transform(shadow_img)\n",
    "            else:\n",
    "                shadow_img = transforms.ToTensor()(shadow_img)\n",
    "            \n",
    "            return shadow_img, shadow_filename, self.original_sizes[idx]\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in __getitem__ for index {idx}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Simplified Local Self-Attention (Local SA) with Random Shuffle (R.S.)\n",
    "class LocalSelfAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=4, window_size=8):\n",
    "        super(LocalSelfAttention, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        logging.debug(f\"Initialized LocalSelfAttention with dim={dim}, num_heads={num_heads}, window_size={window_size}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        try:\n",
    "            B, H, W, C = x.shape\n",
    "            logging.debug(f\"LocalSelfAttention input shape: {x.shape}\")\n",
    "            x = x.view(B, H // self.window_size, self.window_size, W // self.window_size, self.window_size, C)\n",
    "            x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, self.window_size * self.window_size, C)\n",
    "\n",
    "            idx = torch.randperm(x.shape[1])\n",
    "            x = x[:, idx, :]\n",
    "\n",
    "            qkv = self.qkv(x).reshape(x.shape[0], x.shape[1], 3, self.num_heads, self.dim // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "            q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "            attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "            attn = attn.softmax(dim=-1)\n",
    "            x = (attn @ v).transpose(1, 2).reshape(x.shape[0], x.shape[1], self.dim)\n",
    "\n",
    "            reverse_idx = torch.argsort(idx)\n",
    "            x = x[:, reverse_idx, :]\n",
    "\n",
    "            x = self.proj(x)\n",
    "            x = x.view(B, H // self.window_size, W // self.window_size, self.window_size, self.window_size, C)\n",
    "            x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, C)\n",
    "            logging.debug(f\"LocalSelfAttention output shape: {x.shape}\")\n",
    "            return x\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in LocalSelfAttention forward: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# MLP with Structure Modeling\n",
    "class SMLP(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(SMLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim * 4, dim)\n",
    "        )\n",
    "        logging.debug(f\"Initialized SMLP with dim={dim}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        try:\n",
    "            logging.debug(f\"SMLP input shape: {x.shape}\")\n",
    "            x = self.mlp(x)\n",
    "            logging.debug(f\"SMLP output shape: {x.shape}\")\n",
    "            return x\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in SMLP forward: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# HomoBlock\n",
    "class HomoBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads=4, window_size=8):\n",
    "        super(HomoBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = LocalSelfAttention(dim, num_heads, window_size)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.smlp = SMLP(dim)\n",
    "        logging.debug(f\"Initialized HomoBlock with dim={dim}, num_heads={num_heads}, window_size={window_size}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        try:\n",
    "            logging.debug(f\"HomoBlock input shape: {x.shape}\")\n",
    "            x = x + self.attn(self.norm1(x))\n",
    "            x = x + self.smlp(self.norm2(x))\n",
    "            logging.debug(f\"HomoBlock output shape: {x.shape}\")\n",
    "            return x\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in HomoBlock forward: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# HomoFormer Model\n",
    "class HomoFormer(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, dim=32, num_levels=2):\n",
    "        super(HomoFormer, self).__init__()\n",
    "        self.num_levels = num_levels\n",
    "\n",
    "        self.input_proj = nn.Conv2d(in_channels, dim, kernel_size=3, padding=1)\n",
    "\n",
    "        self.down_blocks = nn.ModuleList()\n",
    "        self.down_convs = nn.ModuleList()\n",
    "        current_dim = dim\n",
    "        for i in range(num_levels):\n",
    "            self.down_blocks.append(HomoBlock(current_dim))\n",
    "            self.down_convs.append(nn.Conv2d(current_dim, current_dim * 2, kernel_size=3, stride=2, padding=1))\n",
    "            current_dim *= 2\n",
    "\n",
    "        self.bottleneck = HomoBlock(current_dim)\n",
    "\n",
    "        self.up_blocks = nn.ModuleList()\n",
    "        self.up_convs = nn.ModuleList()\n",
    "        for i in range(num_levels):\n",
    "            self.up_convs.append(nn.ConvTranspose2d(current_dim, current_dim // 2, kernel_size=2, stride=2))\n",
    "            current_dim //= 2\n",
    "            self.up_blocks.append(HomoBlock(current_dim))\n",
    "\n",
    "        self.output_proj = nn.Conv2d(dim, out_channels, kernel_size=3, padding=1)\n",
    "        logging.debug(f\"Initialized HomoFormer with in_channels={in_channels}, out_channels={out_channels}, dim={dim}, num_levels={num_levels}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        try:\n",
    "            logging.debug(f\"HomoFormer input shape: {x.shape}\")\n",
    "            x = self.input_proj(x)\n",
    "            B, C, H, W = x.shape\n",
    "            x = x.permute(0, 2, 3, 1)\n",
    "\n",
    "            skips = []\n",
    "            for i in range(self.num_levels):\n",
    "                logging.debug(f\"Downsampling level {i+1}\")\n",
    "                x = self.down_blocks[i](x)\n",
    "                skips.append(x)\n",
    "                x = x.permute(0, 3, 1, 2)\n",
    "                x = self.down_convs[i](x)\n",
    "                B, C, H, W = x.shape\n",
    "                x = x.permute(0, 2, 3, 1)\n",
    "\n",
    "            logging.debug(\"Processing bottleneck\")\n",
    "            x = self.bottleneck(x)\n",
    "\n",
    "            for i in range(self.num_levels):\n",
    "                logging.debug(f\"Upsampling level {i+1}\")\n",
    "                x = x.permute(0, 3, 1, 2)\n",
    "                x = self.up_convs[i](x)\n",
    "                B, C, H, W = x.shape\n",
    "                x = x.permute(0, 2, 3, 1)\n",
    "                skip = skips[self.num_levels - 1 - i]\n",
    "                x = x + skip\n",
    "                x = self.up_blocks[i](x)\n",
    "\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "            x = self.output_proj(x)\n",
    "            logging.debug(f\"HomoFormer output shape: {x.shape}\")\n",
    "            return torch.sigmoid(x)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in HomoFormer forward: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Function to save images with original resolution\n",
    "def save_images(output_dir, images, filenames, original_sizes):\n",
    "    try:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        logging.debug(f\"Created output directory: {output_dir}\")\n",
    "        \n",
    "        # Check lengths: images.shape[0] is the batch size\n",
    "        batch_size = images.shape[0]  # Get the batch size from the images tensor\n",
    "        if batch_size != len(filenames) or batch_size != len(original_sizes):\n",
    "            logging.error(f\"Length mismatch: images={batch_size}, filenames={len(filenames)}, original_sizes={len(original_sizes)}\")\n",
    "            raise ValueError(\"Length mismatch between images, filenames, and original sizes\")\n",
    "        \n",
    "        # Iterate over the batch\n",
    "        for idx in range(batch_size):\n",
    "            img = images[idx]  # Extract the idx-th image from the batch\n",
    "            fname = filenames[idx]\n",
    "            orig_size = original_sizes[idx]\n",
    "            \n",
    "            output_fname = fname.replace('.png', '_out.png')\n",
    "            output_path = os.path.join(output_dir, output_fname)\n",
    "            img = img.permute(1, 2, 0).detach().cpu().numpy() * 255\n",
    "            img = img.clip(0, 255).astype('uint8')\n",
    "            # Resize to original size\n",
    "            logging.debug(f\"Resizing {output_fname} to original size {orig_size}\")\n",
    "            img = cv2.resize(img, orig_size, interpolation=cv2.INTER_LINEAR)\n",
    "            cv2.imwrite(output_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR), [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "            logging.info(f\"Saved output image: {output_path} with resolution {orig_size}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in save_images: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Custom collate function to handle batching\n",
    "def custom_collate_fn(batch):\n",
    "    # batch is a list of tuples (shadow_img, filename, original_size)\n",
    "    # Each element in batch is the output of __getitem__\n",
    "    \n",
    "    # Separate the elements\n",
    "    shadow_imgs = [item[0] for item in batch]  # List of image tensors\n",
    "    filenames = [item[1] for item in batch]    # List of filenames\n",
    "    original_sizes = [item[2] for item in batch]  # List of original sizes\n",
    "    \n",
    "    # Stack the images into a batch tensor\n",
    "    shadow_imgs = torch.stack(shadow_imgs, dim=0)\n",
    "    \n",
    "    # Return the batched data\n",
    "    return shadow_imgs, filenames, original_sizes\n",
    "\n",
    "# Main execution for testing\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Fix for potential scipy import issue\n",
    "        !pip uninstall -y numpy scipy scikit-image\n",
    "        !pip install numpy==1.23.5 scipy==1.9.3 scikit-image==0.19.3\n",
    "\n",
    "        # Device configuration\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        logging.info(f\"Using device: {device}\")\n",
    "\n",
    "        # Define transform (resize for processing, but we'll resize back to original)\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((128, 128)),  # Resize for processing\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        logging.debug(\"Transform pipeline initialized\")\n",
    "\n",
    "        # Path to your test dataset\n",
    "        # *** UPDATE THE TEST DATASET PATH HERE IF NEEDED ***\n",
    "        # Default assumes test dataset is at \"/kaggle/input/shadowtest\"\n",
    "        # Example: If your test dataset is named \"my-test-data\", use \"/kaggle/input/my-test-data\"\n",
    "        test_data_dir = \"/kaggle/input/shadowtest\"\n",
    "        test_dataset = ShadowRemovalDataset(test_data_dir, transform=test_transform)\n",
    "\n",
    "        # Debug dataset\n",
    "        logging.info(\"Checking test dataset\")\n",
    "        for i in range(min(5, len(test_dataset))):\n",
    "            try:\n",
    "                shadow_img, fname, orig_size = test_dataset[i]\n",
    "                logging.info(f\"Successfully loaded {fname} with original size {orig_size}\")\n",
    "            except ValueError as e:\n",
    "                logging.error(f\"Error loading test dataset item {i}: {e}\")\n",
    "                raise\n",
    "        \n",
    "        # Use the custom collate function in the DataLoader\n",
    "        test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=0, collate_fn=custom_collate_fn)\n",
    "        logging.info(\"DataLoader initialized\")\n",
    "\n",
    "        # Initialize the model\n",
    "        model = HomoFormer(in_channels=3, out_channels=3, dim=32, num_levels=2)\n",
    "        model.to(device)\n",
    "        logging.info(\"Model initialized\")\n",
    "\n",
    "        # Load the trained model weights\n",
    "        # Path updated based on the directory structure of your dataset\n",
    "        model_path = \"/kaggle/input/imageshadowremoval/pytorch/default/1/shadow_removal_model.pth\"\n",
    "        if not os.path.exists(model_path):\n",
    "            logging.error(f\"Model file not found: {model_path}\")\n",
    "            raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "        \n",
    "        # Load the state dict\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        \n",
    "        # If the model was saved with DataParallel, we need to adjust the state dict keys\n",
    "        if list(state_dict.keys())[0].startswith(\"module.\"):\n",
    "            # Remove the \"module.\" prefix from keys\n",
    "            state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "        \n",
    "        model.load_state_dict(state_dict)\n",
    "        logging.info(f\"Loaded model weights from: {model_path}\")\n",
    "\n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "        output_dir = \"/kaggle/working/test_output\"  # Output directory for deshadowed images\n",
    "        logging.info(\"Starting test phase\")\n",
    "        \n",
    "        test_start_time = time.time()\n",
    "        processed_images = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (shadow_img, filenames, original_sizes) in enumerate(test_loader):\n",
    "                try:\n",
    "                    logging.debug(f\"Processing test batch {batch_idx+1}/{len(test_loader)}\")\n",
    "                    shadow_img = shadow_img.to(device)\n",
    "                    output = model(shadow_img)\n",
    "                    # Debug: Log the shapes and lengths\n",
    "                    logging.debug(f\"Batch {batch_idx+1}: output.shape={output.shape}, len(filenames)={len(filenames)}, len(original_sizes)={len(original_sizes)}\")\n",
    "                    save_images(output_dir, output, filenames, original_sizes)\n",
    "                    processed_images += len(filenames)\n",
    "                    logging.info(f\"Processed {processed_images} images so far\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing batch {batch_idx+1}: {str(e)}\")\n",
    "                    raise\n",
    "        test_time = time.time() - test_start_time\n",
    "        avg_time_per_image = test_time / len(test_dataset)\n",
    "        logging.info(\"Test phase completed\")\n",
    "\n",
    "        # Verify the number of output images\n",
    "        output_files = [f for f in os.listdir(output_dir) if f.endswith('.png')]\n",
    "        logging.info(f\"Number of output images generated: {len(output_files)}\")\n",
    "        if len(output_files) != len(test_dataset):\n",
    "            logging.warning(f\"Expected {len(test_dataset)} output images, but generated {len(output_files)}\")\n",
    "\n",
    "        # Create a ZIP file containing all deshadowed images\n",
    "        zip_path = \"/kaggle/working/submission.zip\"\n",
    "        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for fname in output_files:\n",
    "                file_path = os.path.join(output_dir, fname)\n",
    "                zipf.write(file_path, fname)  # Save in root of ZIP\n",
    "        logging.info(f\"Created submission ZIP at: {zip_path}\")\n",
    "\n",
    "        # Verify ZIP contents\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
    "            zip_contents = zipf.namelist()\n",
    "            logging.info(f\"Contents of submission.zip: {zip_contents}\")\n",
    "            png_files_in_zip = [f for f in zip_contents if f.endswith('.png')]\n",
    "            logging.info(f\"Number of .png files in submission.zip: {len(png_files_in_zip)}\")\n",
    "            if len(png_files_in_zip) != len(test_dataset):\n",
    "                logging.error(f\"Expected {len(test_dataset)} .png files in submission.zip, but found {len(png_files_in_zip)}\")\n",
    "                raise ValueError(f\"Expected {len(test_dataset)} .png files in submission.zip, but found {len(png_files_in_zip)}\")\n",
    "\n",
    "        # Print summary\n",
    "        print(f\"Deshadowed test images saved in: {output_dir}\")\n",
    "        print(f\"Submission ZIP file created at: {zip_path}\")\n",
    "        print(f\"Average runtime per image [s]: {avg_time_per_image:.2f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in main execution: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logging.info(\"Script execution completed\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6864208,
     "sourceId": 11022939,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 274770,
     "modelInstanceId": 253311,
     "sourceId": 295886,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 59.272978,
   "end_time": "2025-03-22T06:12:35.798990",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-22T06:11:36.526012",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
